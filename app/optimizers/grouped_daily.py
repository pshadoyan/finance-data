"""
Polygon.io Grouped Daily Bars - Get ALL stocks' OHLC in one API call.
This is the recommended way to download daily data for multiple tickers.
"""

import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Any, Optional
import pandas as pd
from app.polygon_client import PolygonClient

logger = logging.getLogger(__name__)


class GroupedDailyDownloader:
    """
    Download daily bars for ALL stocks using Polygon's Grouped Daily endpoint.
    Much more efficient than individual ticker requests.
    """
    
    def __init__(self, polygon_client: PolygonClient, data_dir: str = "/data"):
        self.client = polygon_client
        self.data_dir = Path(data_dir)
    
    def download_market_day(self, date: str, include_otc: bool = False) -> Dict[str, Any]:
        """
        Download ALL stocks' daily OHLC for a single date.
        
        This replaces thousands of individual API calls with just ONE!
        
        Args:
            date: Date in YYYY-MM-DD format
            include_otc: Include OTC securities
            
        Returns:
            Dict with download results
        """
        try:
            logger.info(f"Downloading grouped daily bars for {date}")
            
            # Use Polygon's grouped daily endpoint
            # This gets ALL stocks in one call!
            response = self.client.client.get_grouped_daily_aggs(
                date=date,
                adjusted=True,
                include_otc=include_otc
            )
            
            if not response or not response.results:
                return {
                    "status": "no_data",
                    "date": date,
                    "message": "No data available for this date"
                }
            
            # Process and save each ticker's data
            saved_count = 0
            for result in response.results:
                ticker = result.get('T', result.get('ticker'))
                if not ticker:
                    continue
                
                # Create data structure
                bar_data = {
                    'timestamp': pd.Timestamp(date),
                    'open': result.get('o'),
                    'high': result.get('h'),
                    'low': result.get('l'),
                    'close': result.get('c'),
                    'volume': result.get('v'),
                    'vwap': result.get('vw'),
                    'transactions': result.get('n')
                }
                
                # Save to file
                ticker_dir = self.data_dir / "equities" / ticker
                ticker_dir.mkdir(parents=True, exist_ok=True)
                
                file_path = ticker_dir / f"{ticker}.1d.parquet"
                
                # Append to existing file or create new
                if file_path.exists():
                    existing_df = pd.read_parquet(file_path)
                    new_df = pd.DataFrame([bar_data])
                    df = pd.concat([existing_df, new_df], ignore_index=True)
                    df = df.drop_duplicates(subset=['timestamp'], keep='last')
                    df = df.sort_values('timestamp')
                else:
                    df = pd.DataFrame([bar_data])
                
                df.to_parquet(file_path, index=False)
                saved_count += 1
            
            logger.info(f"Saved daily bars for {saved_count} tickers from {date}")
            
            return {
                "status": "success",
                "date": date,
                "tickers_saved": saved_count,
                "api_calls_used": 1  # Only ONE API call!
            }
            
        except Exception as e:
            logger.error(f"Failed to download grouped daily bars for {date}: {e}")
            return {
                "status": "error",
                "date": date,
                "error": str(e)
            }
    
    def download_date_range(self, start_date: str, end_date: str) -> Dict[str, Any]:
        """
        Download daily bars for all stocks across a date range.
        
        Args:
            start_date: Start date (YYYY-MM-DD)
            end_date: End date (YYYY-MM-DD)
            
        Returns:
            Summary of downloads
        """
        results = []
        current = datetime.strptime(start_date, '%Y-%m-%d')
        end = datetime.strptime(end_date, '%Y-%m-%d')
        
        total_tickers = set()
        api_calls = 0
        
        while current <= end:
            # Skip weekends
            if current.weekday() < 5:  # Monday=0, Friday=4
                date_str = current.strftime('%Y-%m-%d')
                result = self.download_market_day(date_str)
                
                if result['status'] == 'success':
                    api_calls += 1
                    # Track unique tickers
                    # (would need to modify download_market_day to return ticker list)
                
                results.append(result)
            
            current += timedelta(days=1)
        
        return {
            "status": "completed",
            "start_date": start_date,
            "end_date": end_date,
            "trading_days_processed": len(results),
            "total_api_calls": api_calls,
            "comparison": {
                "old_method_api_calls": len(total_tickers) * len(results),
                "new_method_api_calls": api_calls,
                "efficiency_gain": f"{len(total_tickers)}x faster" if total_tickers else "N/A"
            }
        }


# Example usage comparison:
def compare_methods():
    """
    Compare efficiency of grouped daily vs individual ticker downloads.
    """
    
    # OLD WAY: Download daily data for S&P 500 (500 tickers) for 1 year (252 trading days)
    # API Calls needed: 500 tickers ร 252 days = 126,000 API calls
    # Time at 10 calls/minute: 126,000 รท 10 = 12,600 minutes = 210 hours = 8.75 days!
    
    # NEW WAY: Using grouped daily bars
    # API Calls needed: 252 (one per trading day)
    # Time at 10 calls/minute: 252 รท 10 = 25.2 minutes
    
    # That's 500x more efficient!
    
    print("Efficiency Comparison:")
    print("-" * 50)
    print("Downloading 1 year of daily data for S&P 500:")
    print()
    print("OLD METHOD (Individual ticker calls):")
    print("  - API calls: 126,000")
    print("  - Time: 8.75 days")
    print()
    print("NEW METHOD (Grouped daily bars):")
    print("  - API calls: 252")
    print("  - Time: 25 minutes")
    print()
    print("Improvement: 500x fewer API calls!")
