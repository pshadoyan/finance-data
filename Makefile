# Finance Data Pipeline Makefile
.PHONY: help build up down run stop worker flower logs clean test discover enqueue status

# Default target
help:
	@echo "Finance Data Pipeline - Available Commands:"
	@echo ""
	@echo "  make run        - Full pipeline: build, start services, discover US equities, enqueue jobs"
	@echo "  make build      - Build Docker images"
	@echo "  make up         - Start all services (Redis, App, Worker, Flower)"
	@echo "  make down       - Stop and remove all containers"
	@echo "  make stop       - Stop all containers without removing"
	@echo "  make worker     - Run additional worker instance"
	@echo "  make flower     - Open Flower monitoring UI"
	@echo "  make logs       - Show logs from all services"
	@echo "  make clean      - Remove all containers, volumes, and data"
	@echo ""
	@echo "  make discover   - Discover US equities universe (1000 tickers)"
	@echo "  make enqueue    - Enqueue download jobs for discovered universe"
	@echo "  make status     - Check system status and queue info"
	@echo ""
	@echo "  make test-ticker TICKER=AAPL - Test download for a single ticker"
	@echo ""

# Build Docker images
build:
	@echo "ğŸ”¨ Building Docker images..."
	docker-compose build

# Start all services
up: build
	@echo "ğŸš€ Starting services..."
	docker-compose up -d redis
	@sleep 3
	docker-compose up -d api flower
	@sleep 2
	@echo "âœ… Services started!"
	@echo "   SwaggerUI: http://localhost:8000/docs"
	@echo "   FastAPI: http://localhost:8000"
	@echo "   Flower UI: http://localhost:5555"
	@echo "   Redis: localhost:6379"
	@echo "   Run 'make workers' to start all workers"

# Stop services
down:
	@echo "ğŸ›‘ Stopping services..."
	docker-compose down
	@echo "âœ… Services stopped!"

# Stop without removing containers
stop:
	@echo "â¸ï¸  Pausing services..."
	docker-compose stop

# Full pipeline run (test mode with 100 tickers)
run: up
	@echo "ğŸ¯ Starting full pipeline with parallel processing (TEST MODE - 100 tickers)..."
	@sleep 5
	@echo ""
	@echo "ğŸ‘· Step 1: Starting 6 parallel workers..."
	docker-compose up -d worker-discovery worker-1 worker-2 worker-3 worker-4 worker-5
	@echo "   âœ“ 1 discovery worker + 5 download workers started"
	@echo ""
	@echo "ğŸ“Š Step 2: Discovering US equities (limited to 100 for demo)..."
	docker-compose run --rm app python -m app.cli discover us_equities --limit 100
	@echo ""
	@echo "ğŸ“¥ Step 3: Enqueueing parallel discovery/download jobs..."
	@UNIVERSE_FILE=$$(ls -t universe/us_equities_*.json 2>/dev/null | head -1); \
	if [ -n "$$UNIVERSE_FILE" ]; then \
		echo "   Using universe file: $$UNIVERSE_FILE"; \
		echo "   Each ticker will:"; \
		echo "     1. Discover all available timeframes (1m,5m,15m,30m,1h,2h,4h,1d,1w,1M,1Q,1Y)"; \
		echo "     2. Spawn parallel download tasks for each timeframe"; \
		docker-compose run --rm app python -m app.cli enqueue $$UNIVERSE_FILE \
			--async; \
	else \
		echo "âŒ No universe file found. Run 'make discover' first."; \
	fi
	@echo ""
	@echo "âœ… Pipeline started with 6 parallel workers!"
	@echo "   Monitor progress at http://localhost:5555"
	@echo "   Run 'make logs' to see worker output"

# Full production pipeline (ALL equities in batches)
run-full: up
	@echo "ğŸš€ Starting FULL pipeline with ALL US equities..."
	@sleep 5
	@echo ""
	@echo "ğŸ‘· Step 1: Starting 6 parallel workers..."
	docker-compose up -d worker-discovery worker-1 worker-2 worker-3 worker-4 worker-5
	@echo "   âœ“ 1 discovery worker + 5 download workers started"
	@echo ""
	@echo "ğŸ“Š Step 2: Discovering ALL US equities (up to 15k tickers)..."
	docker-compose run --rm app python -m app.cli discover-all
	@echo ""
	@echo "ğŸ“¦ Step 3: Processing in batches of 100..."
	@UNIVERSE_FILE=$$(ls -t universe/us_equities_*.json 2>/dev/null | head -1); \
	if [ -n "$$UNIVERSE_FILE" ]; then \
		echo "   Using universe file: $$UNIVERSE_FILE"; \
		echo "   Processing first 10 batches (1000 tickers)..."; \
		echo "   Run 'make enqueue-batch START_BATCH=10' to continue with next batches"; \
		docker-compose run --rm app python -m app.cli enqueue-batch $$UNIVERSE_FILE \
			--batch-size 100 \
			--start-batch 0 \
			--max-batches 10 \
			--delay 10; \
	else \
		echo "âŒ No universe file found."; \
	fi
	@echo ""
	@echo "âœ… Full pipeline started!"
	@echo "   Monitor progress at http://localhost:5555"
	@echo "   Continue with: make enqueue-batch START_BATCH=10"

# Run all workers (6 total: 1 discovery + 5 download)
workers:
	@echo "ğŸ‘· Starting all workers..."
	docker-compose up -d worker-discovery worker-1 worker-2 worker-3 worker-4 worker-5
	@echo "âœ… Started 6 workers:"
	@echo "   - 1 discovery worker (handles timeframe discovery)"
	@echo "   - 5 download workers (parallel downloads)"
	@echo "   Monitor at http://localhost:5555"

# Run a single worker (for development)
worker:
	@echo "ğŸ‘· Starting single worker..."
	docker-compose up worker-1

# Open Flower UI
flower:
	@echo "ğŸŒ¸ Opening Flower monitoring UI..."
	@command -v xdg-open >/dev/null 2>&1 && xdg-open http://localhost:5555 || \
	command -v open >/dev/null 2>&1 && open http://localhost:5555 || \
	echo "Please open http://localhost:5555 in your browser"

# Open API SwaggerUI
api-docs:
	@echo "ğŸ“š Opening API documentation..."
	@command -v xdg-open >/dev/null 2>&1 && xdg-open http://localhost:8000/docs || \
	command -v open >/dev/null 2>&1 && open http://localhost:8000/docs || \
	echo "Please open http://localhost:8000/docs in your browser"

# Start API service only
api:
	@echo "ğŸŒ Starting API service..."
	docker-compose up -d redis
	@sleep 2
	docker-compose up api

# Check API health
api-health:
	@echo "ğŸ¥ Checking API health..."
	@curl -s http://localhost:8000/health | python -m json.tool || echo "API not responding"

# Show logs
logs:
	docker-compose logs -f --tail=100

# Show worker logs only
logs-worker:
	docker-compose logs -f --tail=100 worker

# Clean everything
clean:
	@echo "ğŸ§¹ Cleaning up..."
	docker-compose down -v
	rm -rf data/* universe/*
	@echo "âœ… Cleanup complete!"

# Discover universe (limited for testing)
discover:
	@echo "ğŸ” Discovering US equities universe (limited to 100 for testing)..."
	docker-compose run --rm app python -m app.cli discover us_equities --limit 100

# Discover ALL US equities (up to 15k)
discover-full:
	@echo "ğŸ” Discovering ALL US equities (this may take a few minutes)..."
	@echo "   Expected: ~15,000 tickers"
	docker-compose run --rm app python -m app.cli discover-all

# Discover all categories
discover-all:
	@echo "ğŸ” Discovering all categories..."
	docker-compose run --rm app python -m app.cli discover us_equities --limit 100
	docker-compose run --rm app python -m app.cli discover etf --limit 100
	docker-compose run --rm app python -m app.cli discover crypto --limit 50
	docker-compose run --rm app python -m app.cli discover fx --limit 25

# Enqueue jobs with auto-detection
enqueue:
	@UNIVERSE_FILE=$$(ls -t universe/us_equities_*.json 2>/dev/null | head -1); \
	if [ -n "$$UNIVERSE_FILE" ]; then \
		echo "ğŸ“¥ Enqueueing jobs from $$UNIVERSE_FILE with auto-detection..."; \
		docker-compose run --rm app python -m app.cli enqueue $$UNIVERSE_FILE --async; \
	else \
		echo "âŒ No universe file found. Run 'make discover' first."; \
	fi

# Enqueue in batches (for large universes)
enqueue-batch:
	@UNIVERSE_FILE=$$(ls -t universe/us_equities_*.json 2>/dev/null | head -1); \
	if [ -n "$$UNIVERSE_FILE" ]; then \
		echo "ğŸ“¦ Processing universe in batches..."; \
		echo "   File: $$UNIVERSE_FILE"; \
		echo "   Batch size: $${BATCH_SIZE:-100}"; \
		echo "   Starting batch: $${START_BATCH:-0}"; \
		echo "   Max batches: $${MAX_BATCHES:-10}"; \
		docker-compose run --rm app python -m app.cli enqueue-batch $$UNIVERSE_FILE \
			--batch-size $${BATCH_SIZE:-100} \
			--start-batch $${START_BATCH:-0} \
			--max-batches $${MAX_BATCHES:-10} \
			--delay $${DELAY:-5}; \
	else \
		echo "âŒ No universe file found. Run 'make discover' or 'make discover-full' first."; \
	fi

# Enqueue with specific parameters
enqueue-custom:
	@if [ -f universe/us_equities_*.json ]; then \
		UNIVERSE_FILE=$$(ls -t universe/us_equities_*.json | head -1); \
		echo "ğŸ“¥ Enqueueing custom jobs from $$UNIVERSE_FILE..."; \
		docker-compose run --rm app python -m app.cli enqueue $$UNIVERSE_FILE \
			--timeframes $(TIMEFRAMES) \
			--start $(START) \
			--end $(END) \
			--async; \
	else \
		echo "âŒ No universe file found. Run 'make discover' first."; \
	fi

# Check status
status:
	@echo "ğŸ“Š System Status"
	@echo "================"
	@echo ""
	@echo "ğŸ³ Container Status:"
	@docker-compose ps
	@echo ""
	@echo "ğŸ“ˆ Queue Status:"
	@docker-compose exec -T redis redis-cli -h redis LLEN celery || true
	@echo ""
	@echo "ğŸ“ Data Status:"
	@echo "   Universe files: $$(find universe -name "*.json" 2>/dev/null | wc -l)"
	@echo "   Data files: $$(find data -name "*.parquet" 2>/dev/null | wc -l)"
	@echo "   Total size: $$(du -sh data 2>/dev/null | cut -f1)"

# Test single ticker download with auto-detection
test-ticker:
	@if [ -z "$(TICKER)" ]; then \
		echo "âŒ Please specify TICKER, e.g., make test-ticker TICKER=AAPL"; \
	else \
		echo "ğŸ§ª Testing download for $(TICKER) with auto-detection..."; \
		docker-compose run --rm app python -m app.cli run-once $(TICKER) --organize; \
	fi

# Test single ticker with specific parameters
test-ticker-custom:
	@if [ -z "$(TICKER)" ]; then \
		echo "âŒ Please specify TICKER, e.g., make test-ticker-custom TICKER=AAPL TIMEFRAMES=1d,1h"; \
	else \
		echo "ğŸ§ª Testing custom download for $(TICKER)..."; \
		docker-compose run --rm app python -m app.cli run-once $(TICKER) \
			--timeframes $(TIMEFRAMES) \
			--start $(START) \
			--end $(END); \
	fi

# List available universes
list-universes:
	@echo "ğŸ“‹ Available universes:"
	@docker-compose run --rm app python -m app.cli list-universes

# Development mode - mount code for live reload
dev:
	@echo "ğŸ”§ Starting in development mode..."
	docker-compose run --rm -v $$(pwd)/app:/app/app app bash

# Run tests
test:
	@echo "ğŸ§ª Running tests..."
	docker-compose run --rm app python -m pytest tests/ -v

# Quick health check
health:
	@echo "ğŸ¥ Health Check:"
	@docker-compose exec -T redis redis-cli ping && echo "   âœ… Redis: OK" || echo "   âŒ Redis: Failed"
	@curl -s http://localhost:5555/api/workers >/dev/null 2>&1 && echo "   âœ… Flower: OK" || echo "   âŒ Flower: Failed"
	@docker-compose ps | grep -q "worker.*Up" && echo "   âœ… Worker: OK" || echo "   âŒ Worker: Failed"
